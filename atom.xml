<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Macaw AI</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2016-11-10T11:55:43+02:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Michael Anderson & Clint Walker</name>
   <email>themacawai@gmail.com</email>
 </author>

 
 <entry>
   <title>Tensorflow and Deep Learning (without a PhD)</title>
   <link href="http://localhost:4000/2016/11/10/tf-no-phd/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/tf-no-phd</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Starcraft will become the next big playground for AI research as Blizzard and DeepMind team up</title>
   <link href="http://localhost:4000/2016/11/10/starcraft-ai/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/starcraft-ai</id>
   <content type="html">&lt;p&gt;All your base are belong to DeepMind soon enough. That’s right, Blizzard and the team at Google have finally started on the only challenge that matters: finding a way to defeat the &lt;a href=&quot;https://www.youtube.com/watch?v=SAo3QwnPruc&quot;&gt;insane APM masters of Starcraft&lt;/a&gt; using the magic of AI. Great redux on the next big “game” challenge for AI, particularly as “a useful bridge to the messiness of the real-world”. Get in on the action, and don’t forget to check out the post on the &lt;a href=&quot;http://us.battle.net/forums/en/sc2/topic/20751114921&quot;&gt;SC2 API&lt;/a&gt;. And if you’re interested in a bit of background, Gamasutra has a great recap on &lt;a href=&quot;http://www.gamasutra.com/blogs/BenWeber/20161106/284970/A_Brief_History_of_RTS_AI_Research.php&quot;&gt;A Brief History of RTS AI&lt;/a&gt;. &lt;a href=&quot;https://www.youtube.com/watch?v=8fvTxv46ano&quot;&gt;What you say? Make your time. All your base, etc&lt;/a&gt;. Viva la Internet. Carry on.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shining light on Facebook’s AI strategy</title>
   <link href="http://localhost:4000/2016/11/10/shining-light-ai-fb/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/shining-light-ai-fb</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Neural Architecture Search with Reinforcement Learning</title>
   <link href="http://localhost:4000/2016/11/10/openreview-reinforcement-learning/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/openreview-reinforcement-learning</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Using Neural Nets to recognize handwritten digits</title>
   <link href="http://localhost:4000/2016/11/10/nns-for-handwriting/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/nns-for-handwriting</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Andrew Ng on what AI can and can't do right now</title>
   <link href="http://localhost:4000/2016/11/10/ng-on-ai/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/ng-on-ai</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Machine Learning for Software Engineers</title>
   <link href="http://localhost:4000/2016/11/10/ml-for-engineers/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/ml-for-engineers</id>
   <content type="html">&lt;p&gt;A complete daily plan for studying to become a machine learning engineer&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Oxford University’s lip-reading AI is more accurate than humans, but still has a way to go</title>
   <link href="http://localhost:4000/2016/11/10/lip-reading/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/lip-reading</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Halite.io - AI battle bots fight it out to control the grid</title>
   <link href="http://localhost:4000/2016/11/10/halite/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/halite</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Fuzzy.ai - AI powered decision making via an API</title>
   <link href="http://localhost:4000/2016/11/10/fuzzy-ai/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/fuzzy-ai</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Facebook Puts Deep Learning in the Palm of Your Hand</title>
   <link href="http://localhost:4000/2016/11/10/fb-in-your-palm/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/fb-in-your-palm</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>DeepRhyme (D-Prime) – generating dope rhymes with deep learning</title>
   <link href="http://localhost:4000/2016/11/10/d-prime-hiphop/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/d-prime-hiphop</id>
   <content type="html">&lt;p&gt;From self-proclaimed “white boy, straight outta Cambridge, UK” comes a fun ML driven rapbot. Talks through some of the techniques used (&lt;a href=&quot;http://www.aclweb.org/anthology/D13-1022&quot;&gt;beam search&lt;/a&gt;) as well as challenges and failures of the model (ABAB type rhyming). It also touches on the consequences of your training data having biases that may not be politically correct or socially acceptable. Discovering that your ML model is a hardcore misogynist can be a shock, and the author notes that “machine learning algorithms like this rarely act how you want them to without some supervision”. Also references the excellent &lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;RNN post from Andrej Karpathy&lt;/a&gt;, which is definitely worth a read.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Cybersecurity’s Next Step: Artificial Intelligence Is Helping Predict, Prevent, And Defeat Attacks</title>
   <link href="http://localhost:4000/2016/11/10/cybersec/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/cybersec</id>
   <content type="html">&lt;p&gt;The explosion into mainstream consciousness of cybersecurity has spawned a unique niche of startups that are applying AI techniques to this field. Particularly as an approach to mitigating zero-day attacks “to differentiate benign or harmful activity on a system or network”. This article shows off some of the recent trends and correlations of interest in the terms, and provides a handy look at the companies and startups operating in the intersection of AI and cybersecurity.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Competitive Landscape for Machine Intelligence</title>
   <link href="http://localhost:4000/2016/11/10/ai-cos/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/ai-cos</id>
   <content type="html">&lt;p&gt;List of startups competing in AI in 2016&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Adobe Sensei</title>
   <link href="http://localhost:4000/2016/11/10/adobe-sensei/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/adobe-sensei</id>
   <content type="html">&lt;p&gt;“From image matching across millions of assets, to understanding the meaning and sentiment of documents, to finely targeting important audience segments, Adobe Sensei does it all.” (Ed: Yes but &lt;a href=&quot;https://www.youtube.com/user/Blendtec&quot;&gt;will it blend?&lt;/a&gt;)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Neural Networks for the Prediction of Organic Chemistry Reactions</title>
   <link href="http://localhost:4000/2016/11/10/acs-organic-chem/"/>
   <updated>2016-11-10T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/10/acs-organic-chem</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Finding Local Minima for Nonconvex Optimization in Linear Time</title>
   <link href="http://localhost:4000/2016/11/03/arxiv-1611-01146v1/"/>
   <updated>2016-11-03T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/03/arxiv-1611-01146v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Learning to Pivot with Adversarial Networks</title>
   <link href="http://localhost:4000/2016/11/03/arxiv-1611-01046v1/"/>
   <updated>2016-11-03T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/03/arxiv-1611-01046v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Maximizing Investment Value of Small-Scale PV in a Smart Grid   Environment</title>
   <link href="http://localhost:4000/2016/11/03/arxiv-1611-00890v1/"/>
   <updated>2016-11-03T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/03/arxiv-1611-00890v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Recurrent Neural Networks for Spatiotemporal Dynamics of Intrinsic   Networks from fMRI Data</title>
   <link href="http://localhost:4000/2016/11/03/arxiv-1611-00864v1/"/>
   <updated>2016-11-03T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/03/arxiv-1611-00864v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>IBM’s Watson AI Recommends Same Treatment as Doctors in 99% of Cancer Cases</title>
   <link href="http://localhost:4000/2016/11/02/watson-cancer-diagnosis/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/watson-cancer-diagnosis</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>She's just not that into you - why our AI assistants feel so distant</title>
   <link href="http://localhost:4000/2016/11/02/shes-not-that-into-you/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/shes-not-that-into-you</id>
   <content type="html">&lt;p&gt;“The quest for better AI assistants begins with personal data privacy”. Digital assistants have underwhelmed in part because they have limited to no access to our personal “knowledge graph” - our calendars, social networks, email… This short article that raises the questions of trust and Private By Design, with the promise of what a genuinely personal AI could be if we weren’t already vaguely terrified of the tech monopolies who already play fast and loose with our private details.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Zoom, enhance! Hallucinating super resolution</title>
   <link href="http://localhost:4000/2016/11/02/neural-net-enhancer/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/neural-net-enhancer</id>
   <content type="html">&lt;p&gt;As seen on TV: “Bring up that security footage, the 320x320 pixelated matchbox, yeah that one, hmm what’s that in the corner, zoom, zoom, rotate, zoom, enhance. ENHANCE! OMG WE GOT IT” etc. Yeah. ‘Enhance’. Making anyone who knows anything roll their eyes since the eighties (anyone got any earlier references? Let us know!!). But here we have a legitimate contender for making that scenario less eye-roll-y: this neat setup basically hallucinates image details (remember &lt;a href=&quot;https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Deep Dream&lt;/a&gt;) based on training data. The closer the domain match (training data to image being enhanced), the better the results. Of course, it’s basically just an (automated) artist’s “impression”, so lets hope our justice system never takes these results too seriously.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Microsoft Concept Graph for short text understanding</title>
   <link href="http://localhost:4000/2016/11/02/ms-concept-graph/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/ms-concept-graph</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Making Neural Networks explain themselves for their decisions</title>
   <link href="http://localhost:4000/2016/11/02/making-them-explain/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/making-them-explain</id>
   <content type="html">&lt;p&gt;Neural Networks are fun, but weird right? &lt;em&gt;So&lt;/em&gt; weird that throwing random noise at them to reveal underlying structure makes us go “oooow look at all that weirdness” (remember &lt;a href=&quot;https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Deep Dream&lt;/a&gt;). And despite their impressive results, one of the drawbacks to Neural Networks is that they are often the blackest of black boxes. Great results, no idea why. Not content with this, some MIT researchers have proposed a technique to reveal the underlying rationales for the decisions made by these systems, by mapping between decision outputs and a corpus of “short and coherent” pieces of text rationales “sufficient for making the same prediction”. Giving us humans a few explanatory crumbs to feel comfortable with machine decisions will go a long way to assuaging that vague “yes but why” feeling that may linger, particularly in more sensitive areas like medicine or you know, &lt;a href=&quot;http://macawai.com/weekly/2016-10-27-ethical-determinism-trolley-terminator-unemployment&quot;&gt;killer robots&lt;/a&gt;. For as the authors say in their opening “Prediction without justification has limited applicability”. Check out the full MIT research paper &lt;a href=&quot;https://people.csail.mit.edu/taolei/papers/emnlp16_rationale.pdf&quot;&gt;“Rationalizing Neural Predictions”&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>AI chip start-up Graphcore raised $30m to take on the World’s AI giants</title>
   <link href="http://localhost:4000/2016/11/02/graphcore/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/graphcore</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>exprso: an R-package for the rapid implementation of machine learning algorithms</title>
   <link href="http://localhost:4000/2016/11/02/exprso-r-package/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/exprso-r-package</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>AI Pioneer Yoshua Bengio Is Launching Element AI, a Deep-Learning Incubator</title>
   <link href="http://localhost:4000/2016/11/02/element-ai-incubator/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/element-ai-incubator</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Blood, Sweat and Years: Raising Money As A Deep Learning Startup</title>
   <link href="http://localhost:4000/2016/11/02/deep-startups-funding/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/deep-startups-funding</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Data science reading resources</title>
   <link href="http://localhost:4000/2016/11/02/data-science-resources/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/data-science-resources</id>
   <content type="html">&lt;p&gt;Curated list of experts, learning and newsletters/podcasts from the community at Kaggle&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Asteria - AI hardware in your pocket</title>
   <link href="http://localhost:4000/2016/11/02/asteria/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/asteria</id>
   <content type="html">&lt;p&gt;Straight from the movie “Her”, you too can now have a handy block of pocket smart to make you feel less alone.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Deep Convolutional Neural Network Design Patterns</title>
   <link href="http://localhost:4000/2016/11/02/arxiv-1611-00847v1/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/arxiv-1611-00847v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Extensions and Limitations of the Neural GPU</title>
   <link href="http://localhost:4000/2016/11/02/arxiv-1611-00736v1/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/arxiv-1611-00736v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Deep counter networks for asynchronous event-based processing</title>
   <link href="http://localhost:4000/2016/11/02/arxiv-1611-00710v1/"/>
   <updated>2016-11-02T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/02/arxiv-1611-00710v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Surrogate-Assisted Partial Order-based Evolutionary Optimisation</title>
   <link href="http://localhost:4000/2016/11/01/arxiv-1611-00260v1/"/>
   <updated>2016-11-01T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/11/01/arxiv-1611-00260v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Full-Capacity Unitary Recurrent Neural Networks</title>
   <link href="http://localhost:4000/2016/10/31/arxiv-1611-00035v1/"/>
   <updated>2016-10-31T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/31/arxiv-1611-00035v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Tensor Switching Networks</title>
   <link href="http://localhost:4000/2016/10/31/arxiv-1610-10087v1/"/>
   <updated>2016-10-31T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/31/arxiv-1610-10087v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large   Vocabulary Speech Recognition</title>
   <link href="http://localhost:4000/2016/10/31/arxiv-1610-09975v1/"/>
   <updated>2016-10-31T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/31/arxiv-1610-09975v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Depth Separation in ReLU Networks for Approximating Smooth Non-Linear   Functions</title>
   <link href="http://localhost:4000/2016/10/31/arxiv-1610-09887v1/"/>
   <updated>2016-10-31T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/31/arxiv-1610-09887v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>A Survey of Brain Inspired Technologies for Engineering</title>
   <link href="http://localhost:4000/2016/10/31/arxiv-1610-09882v1/"/>
   <updated>2016-10-31T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/31/arxiv-1610-09882v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Feature-Augmented Neural Networks for Patient Note De-identification</title>
   <link href="http://localhost:4000/2016/10/30/arxiv-1610-09704v1/"/>
   <updated>2016-10-30T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/30/arxiv-1610-09704v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Compact Deep Convolutional Neural Networks With Coarse Pruning</title>
   <link href="http://localhost:4000/2016/10/30/arxiv-1610-09639v1/"/>
   <updated>2016-10-30T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/30/arxiv-1610-09639v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Generalized Haar Filter based Deep Networks for Real-Time Object   Detection in Traffic Scene</title>
   <link href="http://localhost:4000/2016/10/30/arxiv-1610-09609v1/"/>
   <updated>2016-10-30T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/30/arxiv-1610-09609v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>A Theoretical Study of The Relationship Between Whole An ELM Network and   Its Subnetworks</title>
   <link href="http://localhost:4000/2016/10/30/arxiv-1610-09608v1/"/>
   <updated>2016-10-30T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/30/arxiv-1610-09608v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Machine learning methods for accurate delineation of tumors in PET   images</title>
   <link href="http://localhost:4000/2016/10/29/arxiv-1610-09493v1/"/>
   <updated>2016-10-29T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/29/arxiv-1610-09493v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Building Energy Load Forecasting using Deep Neural Networks</title>
   <link href="http://localhost:4000/2016/10/29/arxiv-1610-09460v1/"/>
   <updated>2016-10-29T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/29/arxiv-1610-09460v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Top Whitehouse Economist: AI isn't going to steal jobs</title>
   <link href="http://localhost:4000/2016/10/26/whitehouse-jobs-are-safe/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/whitehouse-jobs-are-safe</id>
   <content type="html">&lt;p&gt;Some jobs get replaced, but new ones get created. “I see no reason to think this time is going to be any different,” said Furman (the economist).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Udacity Artificial Intelligence Nanodegree program</title>
   <link href="http://localhost:4000/2016/10/26/udacity-ai-degree/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/udacity-ai-degree</id>
   <content type="html">&lt;p&gt;2 terms, 3 months and $800 each, starting Jan 2017&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Smart Traffic Lights that could shorten your commute</title>
   <link href="http://localhost:4000/2016/10/26/traffic-commute/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/traffic-commute</id>
   <content type="html">&lt;p&gt;Pittsburgh is rolling out AI controlled traffic lights by startup &lt;a href=&quot;https://www.surtrac.net/&quot;&gt;Surtrac&lt;/a&gt;, reducing travel time by up to 25% and idle time by up to 40%.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Pentagon’s ‘Terminator Conundrum’: Robots That Could Kill on Their Own</title>
   <link href="http://localhost:4000/2016/10/26/terminator-conundrum/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/terminator-conundrum</id>
   <content type="html">&lt;p&gt;The US has put AI at the center of its defense strategy. So at what point do we permit a neural net to pull a trigger? “The debate within the military is no longer about whether to build autonomous weapons but how much independence to give them”. Yeah. Follow the Campaign to &lt;a href=&quot;http://www.stopkillerrobots.org/&quot;&gt;Stop Killer Robots&lt;/a&gt;, who presented their most &lt;a href=&quot;http://www.stopkillerrobots.org/2016/10/unga71/&quot;&gt;recent case to the UN General Assembley&lt;/a&gt; only a few days ago.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Nightmare Machine</title>
   <link href="http://localhost:4000/2016/10/26/nightmare/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/nightmare</id>
   <content type="html">&lt;p&gt;MIT’s deep learning horror imagery generator&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>AI can learn from data without ever having access to it</title>
   <link href="http://localhost:4000/2016/10/26/learn-without-access/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/learn-without-access</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Keras Autoencoder network for learning a continuous representation of molecular structures</title>
   <link href="http://localhost:4000/2016/10/26/keras-molecule/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/keras-molecule</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>When AI Journalism goes bad</title>
   <link href="http://localhost:4000/2016/10/26/journalism-goes-bad/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/journalism-goes-bad</id>
   <content type="html">&lt;p&gt;Or, what happens when journalists who don’t know very much start prognosticating on AI safety (in short: bad AI journalism can ruin the science). A lucid critique from Future of Life. Follow this up with &lt;a href=&quot;http://www.3ammagazine.com/3am/cheerleading-agenda-press-covers-science/&quot;&gt;How the Press covers Science&lt;/a&gt;, a look at the impacts of agendas, PR, money and narratives are affecting science journalism in general.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Facebook on building an efficient neural language model over a billion words</title>
   <link href="http://localhost:4000/2016/10/26/fb-neural-net/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/fb-neural-net</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Deep Learning Papers - reading roadmap</title>
   <link href="http://localhost:4000/2016/10/26/deep-learning-papers/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/deep-learning-papers</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>China's big AI push</title>
   <link href="http://localhost:4000/2016/10/26/china-big-ai-push/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/china-big-ai-push</id>
   <content type="html">&lt;p&gt;A provoking opinion piece on key factors driving China’s foray into AI&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The Automatic Statistician</title>
   <link href="http://localhost:4000/2016/10/26/auto-stat/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/auto-stat</id>
   <content type="html">&lt;p&gt;AI for data science and automatic exploratory data analysis&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Andrew Ng on the transformative impacts of AI on industry</title>
   <link href="http://localhost:4000/2016/10/26/andrew-ng-on-ai-electricity/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/andrew-ng-on-ai-electricity</id>
   <content type="html">&lt;p&gt;“The biggest ethical question today is actually not AI sentience but unemployment” - Ng&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>AI and Ethical Determinism</title>
   <link href="http://localhost:4000/2016/10/26/ai-ethical-determinism/"/>
   <updated>2016-10-26T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/26/ai-ethical-determinism</id>
   <content type="html">&lt;p&gt;The challenges of encoding ethical behaviour - specifically discussing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Trolley_problem&quot;&gt;Trolley Problem&lt;/a&gt; and MIT’s &lt;a href=&quot;http://moralmachine.mit.edu/&quot;&gt;“The Moral Machine”&lt;/a&gt;, a nifty survey where you get to choose who dies. Happy Thursday!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Big Models for Big Data using Multi objective averaged one dependence   estimators</title>
   <link href="http://localhost:4000/2016/10/25/arxiv-1610-07752v1/"/>
   <updated>2016-10-25T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/25/arxiv-1610-07752v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Operational calculus on programming spaces and generalized tensor   networks</title>
   <link href="http://localhost:4000/2016/10/25/arxiv-1610-07690v1/"/>
   <updated>2016-10-25T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/25/arxiv-1610-07690v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Surprisal-Driven Zoneout</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07675v4/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07675v4</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Surprisal-Driven Zoneout</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07675v3/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07675v3</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Learning to Reason With Adaptive Computation</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07647v1/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07647v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>STDP allows close-to-optimal spatiotemporal spike pattern detection by   single coincidence detector neurons</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07355v1/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07355v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Representation Learning with Deconvolution for Multivariate Time Series   Classification and Visualization</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07258v2/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07258v2</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Representation Learning with Deconvolution for Multivariate Time Series   Classification and Visualization</title>
   <link href="http://localhost:4000/2016/10/24/arxiv-1610-07258v1/"/>
   <updated>2016-10-24T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/24/arxiv-1610-07258v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Hybrid clustering-classification neural network in the medical   diagnostics of reactive arthritis</title>
   <link href="http://localhost:4000/2016/10/21/arxiv-1610-07857v1/"/>
   <updated>2016-10-21T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/21/arxiv-1610-07857v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Talos Secure Workstation</title>
   <link href="http://localhost:4000/2016/10/20/talos-workstation/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/talos-workstation</id>
   <content type="html">&lt;p&gt;Crowd-sourced ATX-compatible, workstation-class mainboard for the IBM POWER8 processor&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>How quantum effects could improve AI</title>
   <link href="http://localhost:4000/2016/10/20/phys-quantum-effects/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/phys-quantum-effects</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>OpenAI is using Reddit to teach an AI how to speak</title>
   <link href="http://localhost:4000/2016/10/20/openai-reddit-speech/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/openai-reddit-speech</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Obama aims to rewrite the Social Contract in the age of AI</title>
   <link href="http://localhost:4000/2016/10/20/obama-on-ai/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/obama-on-ai</id>
   <content type="html">&lt;p&gt;A short video (9 min) of Obama talking with Wired about AI and its impacts on economic and social models, particularly how we mitigate the potentially destabilising effects of an AI-first world (in particular, employment, wage-suppression and inequality). See the related Whitehouse paper on &lt;a href=&quot;https://www.whitehouse.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf&quot;&gt;“Preparing for the Future of AI”&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Numer.ai - A hedge fund built by a global community of anonymous data scientists</title>
   <link href="http://localhost:4000/2016/10/20/numerai/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/numerai</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Nothing pixelated will stay safe on the internet</title>
   <link href="http://localhost:4000/2016/10/20/nothing-pixelated-will-stay-safe/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/nothing-pixelated-will-stay-safe</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Hybrid computing using a neural network with dynamic external memory</title>
   <link href="http://localhost:4000/2016/10/20/nature-Neural-network-with-dynamic-external-memory/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/nature-Neural-network-with-dynamic-external-memory</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Microsoft researchers reach human parity in conversational speech recognition</title>
   <link href="http://localhost:4000/2016/10/20/ms-speech-human-parity/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/ms-speech-human-parity</id>
   <content type="html">&lt;p&gt;Word Error Rate (WER) on the industry standard Switchboard task down to 5.9 by the team at Microsoft (about equal to human transcription error rates of the same conversation) using their open source &lt;a href=&quot;https://www.cntk.ai/&quot;&gt;Computational Network Toolkit&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Microsoft Light Gradient Boosting Machine</title>
   <link href="http://localhost:4000/2016/10/20/ms-lgbm/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/ms-lgbm</id>
   <content type="html">&lt;p&gt;Fast, distributed, high performance gradient boosting framework&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Keras.js - Run trained Keras models in the browser, with GPU support</title>
   <link href="http://localhost:4000/2016/10/20/keras-js/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/keras-js</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>The UC Berkely Center for Human Compatible AI</title>
   <link href="http://localhost:4000/2016/10/20/human-compatible-ai/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/human-compatible-ai</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>EFF on Facial Recognition’s threat to privacy - it's worse than anyone thought</title>
   <link href="http://localhost:4000/2016/10/20/eff-facial-recognition/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/eff-facial-recognition</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Civilization VI AI Battle Royale</title>
   <link href="http://localhost:4000/2016/10/20/civ-vi-ai/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/civ-vi-ai</id>
   <content type="html">&lt;p&gt;Watch 8 AIs battle for global supremacy in the latest Civ launch&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>China has overtaken the US in AI research</title>
   <link href="http://localhost:4000/2016/10/20/china-has-overtaken-the-u-s-in-ai-research/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/china-has-overtaken-the-u-s-in-ai-research</id>
   <content type="html">&lt;p&gt;The US appears to be lagging China in AI research, at least by journal articles that mention “deep learning” or “deep neural network”. Estimates that current levels of R&amp;amp;D spending on AI are one-half to one-quarter of the levels that would be best for economic growth. And, like this article says, if the US lags in research, other countries might get to “dictate how the tech is used”. :rage:&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>An Evolving Neuro-Fuzzy System with Online Learning/Self-learning</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06488v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06488v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Adaptive Forecasting of Non-Stationary Nonlinear Time Series Based on   the Evolving Weighted Neuro-Neo-Fuzzy-ANARX-Model</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06486v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06486v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>A Multidimensional Cascade Neuro-Fuzzy System with Neuron Pool   Optimization in Each Cascade</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06485v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06485v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>An Evolving Cascade System Based on A Set Of Neo Fuzzy Nodes</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06484v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06484v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06483v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06483v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Reasoning with Memory Augmented Neural Networks for Language   Comprehension</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06454v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06454v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>A Growing Long-term Episodic &amp; Semantic Memory</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06402v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06402v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Clinical Text Prediction with Numerically Grounded Conditional Language   Models</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06370v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06370v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Deep Neural Networks for Improved, Impromptu Trajectory Tracking of   Quadrotors</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06283v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06283v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Embodiment of Learning in Electro-Optical Signal Processors</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06269v2/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06269v2</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Embodiment of Learning in Electro-Optical Signal Processors</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06269v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06269v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Online Training of an Opto-Electronic Reservoir Computer Applied to   Real-Time Channel Equalisation</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06268v1/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06268v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Using Fast Weights to Attend to the Recent Past</title>
   <link href="http://localhost:4000/2016/10/20/arxiv-1610-06258v2/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/arxiv-1610-06258v2</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>AI Open Network</title>
   <link href="http://localhost:4000/2016/10/20/ai-on/"/>
   <updated>2016-10-20T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/20/ai-on</id>
   <content type="html">&lt;p&gt;An open community dedicated to advancing AI by highlighting research problems, connecting researchers and providing a learning environment.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Streaming Normalization: Towards Simpler and More Biologically-plausible   Normalizations for Online and Recurrent Learning</title>
   <link href="http://localhost:4000/2016/10/19/arxiv-1610-06160v1/"/>
   <updated>2016-10-19T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/19/arxiv-1610-06160v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;We systematically explored a spectrum of normalization algorithms related to
Batch Normalization (BN) and propose a generalized formulation that
simultaneously solves two major limitations of BN: (1) online learning and (2)
recurrent learning. Our proposal is simpler and more biologically-plausible.
Unlike previous approaches, our technique can be applied out of the box to all
learning scenarios (e.g., online learning, batch learning, fully-connected,
convolutional, feedforward, recurrent and mixed — recurrent and
convolutional) and compare favorably with existing approaches. We also propose
Lp Normalization for normalizing by different orders of statistical moments. In
particular, L1 normalization is well-performing, simple to implement, fast to
compute, more biologically-plausible and thus ideal for GPU or hardware
implementations.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Particle Swarm Optimization for Generating Fuzzy Reinforcement Learning   Policies</title>
   <link href="http://localhost:4000/2016/10/19/arxiv-1610-05984v1/"/>
   <updated>2016-10-19T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/19/arxiv-1610-05984v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Fuzzy controllers are known to serve as efficient and interpretable system
controllers for continuous state and action spaces. To date these controllers
have been constructed by hand, or automatically trained either on expert
generated problem specific cost functions or by incorporating detailed
knowledge about the optimal control strategy. Both requirements for automatic
training processes are not given in the majority of real world reinforcement
learning (RL) problems. We introduce a new particle swarm reinforcement
learning (PSRL) approach which is capable of constructing fuzzy RL policies
solely by training parameters on world models produced from randomly generated
samples of the real system. This approach relates self-organizing fuzzy
controllers to model-based RL for the first time. PSRL can be used
straightforward on any RL problem, which is demonstrated on three standard RL
benchmarks, mountain car, cart pole balancing and cart pole swing up. Our
experiments yielded high performing and well interpretable fuzzy policies.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Scaling Up MAP-Elites Using Centroidal Voronoi Tessellations</title>
   <link href="http://localhost:4000/2016/10/18/arxiv-1610-05729v1/"/>
   <updated>2016-10-18T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/18/arxiv-1610-05729v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;The recently introduced Multi-dimensional Archive of Phenotypic Elites
(MAP-Elites) is an evolutionary algorithm capable of producing a large archive
of diverse, high-performing solutions in a single run. It works by discretizing
a continuous feature space into unique regions according to the desired
discretization per dimension. While simple, this algorithm has a main drawback:
it cannot scale to high-dimensional feature spaces since the number of regions
increase exponentially with the number of dimensions. In this paper, we address
this limitation by introducing a simple extension of MAP-Elites that has a
constant, pre-defined number of regions irrespective of the dimensionality of
the feature space. Our main insight is that methods from computational geometry
could partition a high-dimensional space into well-spread geometric regions. In
particular, our algorithm uses a centroidal Voronoi tessellation (CVT) to
divide the feature space into a desired number of regions; it then places every
generated individual in its closest region, replacing a less fit one if the
region is already occupied. We demonstrate the effectiveness of the new
“CVT-MAP-Elites” algorithm in high-dimensional feature spaces through
comparisons against MAP-Elites in a hexapod locomotion task.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Design Mining Microbial Fuel Cell Cascades</title>
   <link href="http://localhost:4000/2016/10/18/arxiv-1610-05716v1/"/>
   <updated>2016-10-18T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/18/arxiv-1610-05716v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Microbial fuel cells (MFCs) perform wastewater treatment and electricity
production through the conversion of organic matter using microorganisms. For
practical applications, it has been suggested that greater efficiency can be
achieved by arranging multiple MFC units into physical stacks in a cascade with
feedstock flowing sequentially between units. In this paper, we investigate the
use of computational intelligence to physically explore and optimise
(potentially) heterogeneous MFC designs in a cascade, i.e. without simulation.
Conductive structures are 3-D printed and inserted into the anodic chamber of
each MFC unit, augmenting a carbon fibre veil anode and affecting the
hydrodynamics, including the feedstock volume and hydraulic retention time, as
well as providing unique habitats for microbial colonisation. We show that it
is possible to use design mining to identify new conductive inserts that
increase both the cascade power output and power density.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Online Contrastive Divergence with Generative Replay: Experience Replay   without Storing Data</title>
   <link href="http://localhost:4000/2016/10/18/arxiv-1610-05555v1/"/>
   <updated>2016-10-18T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/18/arxiv-1610-05555v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Conceived in the early 1990s, Experience Replay (ER) has been shown to be a
successful mechanism to allow online learning algorithms to reuse past
experiences. Traditionally, ER can be applied to all machine learning paradigms
(i.e., unsupervised, supervised, and reinforcement learning). Recently, ER has
contributed to improving the performance of deep reinforcement learning. Yet,
its application to many practical settings is still limited by the memory
requirements of ER, necessary to explicitly store previous observations. To
remedy this issue, we explore a novel approach, Online Contrastive Divergence
with Generative Replay (OCD_GR), which uses the generative capability of
Restricted Boltzmann Machines (RBMs) instead of recorded past experiences. The
RBM is trained online, and does not require the system to store any of the
observed data points. We compare OCD_GR to ER on 9 real-world datasets,
considering a worst-case scenario (data points arriving in sorted order) as
well as a more realistic one (sequential random-order data points). Our results
show that in 64.28% of the cases OCD_GR outperforms ER and in the remaining
35.72% it has an almost equal performance, while having a considerably reduced
space complexity (i.e., memory usage) at a comparable time complexity.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Evolving the Structure of Evolution Strategies</title>
   <link href="http://localhost:4000/2016/10/17/arxiv-1610-05231v1/"/>
   <updated>2016-10-17T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/17/arxiv-1610-05231v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Various variants of the well known Covariance Matrix Adaptation Evolution
Strategy (CMA-ES) have been proposed recently, which improve the empirical
performance of the original algorithm by structural modifications. However, in
practice it is often unclear which variation is best suited to the specific
optimization problem at hand. As one approach to tackle this issue, algorithmic
mechanisms attached to CMA-ES variants are considered and extracted as
functional \emph{modules}, allowing for combinations of them. This leads to a
configuration space over ES structures, which enables the exploration of
algorithm structures and paves the way toward novel algorithm generation.
Specifically, eleven modules are incorporated in this framework with two or
three alternative configurations for each module, resulting in $4\,608$
algorithms. A self-adaptive Genetic Algorithm (GA) is used to efficiently
evolve effective ES-structures for given classes of optimization problems,
outperforming any classical CMA-ES variants from literature. The proposed
approach is evaluated on noiseless functions from BBOB suite. Furthermore, such
an observation is again confirmed on different function groups and
dimensionality, indicating the feasibility of ES configuration on real-world
problem classes.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Weekly maintenance scheduling using exact and genetic methods</title>
   <link href="http://localhost:4000/2016/10/17/arxiv-1610-05016v1/"/>
   <updated>2016-10-17T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/17/arxiv-1610-05016v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;The weekly maintenance schedule specifies when maintenance activities should
be performed on the equipment, taking into account the availability of workers
and maintenance bays, and other operational constraints. The current approach
to generating this schedule is labour intensive and requires coordination
between the maintenance schedulers and operations staff to minimise its impact
on the operation of the mine. This paper presents methods for automatically
generating this schedule from the list of maintenance tasks to be performed,
the availability roster of the maintenance staff, and time windows in which
each piece of equipment is available for maintenance. Both Mixed-Integer Linear
Programming (MILP) and genetic algorithms are evaluated, with the genetic
algorithm shown to significantly outperform the MILP. Two fitness functions for
the genetic algorithm are also examined, with a linear fitness function
outperforming an inverse fitness function by up to 5% for the same calculation
time. The genetic algorithm approach is computationally fast, allowing the
schedule to be rapidly recalculated in response to unexpected delays and
breakdowns.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Cached Long Short-Term Memory Neural Networks for Document-Level   Sentiment Classification</title>
   <link href="http://localhost:4000/2016/10/17/arxiv-1610-04989v1/"/>
   <updated>2016-10-17T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/17/arxiv-1610-04989v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Recently, neural networks have achieved great success on sentiment
classification due to their ability to alleviate feature engineering. However,
one of the remaining challenges is to model long texts in document-level
sentiment classification under a recurrent architecture because of the
deficiency of the memory unit. To address this problem, we present a Cached
Long Short-Term Memory neural networks (CLSTM) to capture the overall semantic
information in long texts. CLSTM introduces a cache mechanism, which divides
memory into several groups with different forgetting rates and thus enables the
network to keep sentiment information better within a recurrent unit. The
proposed CLSTM outperforms the state-of-the-art models on three publicly
available document-level sentiment analysis datasets.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Multiple Instance Fuzzy Inference Neural Networks</title>
   <link href="http://localhost:4000/2016/10/17/arxiv-1610-04973v1/"/>
   <updated>2016-10-17T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/17/arxiv-1610-04973v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Fuzzy logic is a powerful tool to model knowledge uncertainty, measurements
imprecision, and vagueness. However, there is another type of vagueness that
arises when data have multiple forms of expression that fuzzy logic does not
address quite well. This is the case for multiple instance learning problems
(MIL). In MIL, an object is represented by a collection of instances, called a
bag. A bag is labeled negative if all of its instances are negative, and
positive if at least one of its instances is positive. Positive bags encode
ambiguity since the instances themselves are not labeled. In this paper, we
introduce fuzzy inference systems and neural networks designed to handle bags
of instances as input and capable of learning from ambiguously labeled data.
First, we introduce the Multiple Instance Sugeno style fuzzy inference
(MI-Sugeno) that extends the standard Sugeno style inference to handle
reasoning with multiple instances. Second, we use MI-Sugeno to define and
develop Multiple Instance Adaptive Neuro Fuzzy Inference System (MI-ANFIS). We
expand the architecture of the standard ANFIS to allow reasoning with bags and
derive a learning algorithm using backpropagation to identify the premise and
consequent parameters of the network. The proposed inference system is tested
and validated using synthetic and benchmark datasets suitable for MIL problems.
We also apply the proposed MI-ANFIS to fuse the output of multiple
discrimination algorithms for the purpose of landmine detection using Ground
Penetrating Radar.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Hadamard Product for Low-rank Bilinear Pooling</title>
   <link href="http://localhost:4000/2016/10/14/arxiv-1610-04325v1/"/>
   <updated>2016-10-14T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/14/arxiv-1610-04325v1</id>
   <content type="html">&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Bilinear models provide rich representations compared to linear models. They
have been applied in various visual tasks, such as object recognition,
segmentation, and visual question-answering, to get state-of-the-art
performances taking advantage of the expanded representations. However,
bilinear representations tend to be high-dimensional, limiting the
applicability to computationally complex tasks. We propose low-rank bilinear
neural networks using Hadamard product (element-wise multiplication), commonly
implemented in many scientific computing frameworks. We show that our model
outperforms compact bilinear pooling in visual question-answering tasks, having
a better parsimonious property.&lt;/p&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>RetiNet: Automatic AMD identification in OCT volumetric data</title>
   <link href="http://localhost:4000/2016/10/12/arxiv-1610-03628v1/"/>
   <updated>2016-10-12T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/12/arxiv-1610-03628v1</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Optimizing Memory Efficiency for Deep Convolutional Neural Networks on   GPUs</title>
   <link href="http://localhost:4000/2016/10/12/arxiv-1610-03618v1/"/>
   <updated>2016-10-12T00:00:00+02:00</updated>
   <id>http://localhost:4000/2016/10/12/arxiv-1610-03618v1</id>
   <content type="html">&lt;!--more--&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;blockquote&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 

</feed>
