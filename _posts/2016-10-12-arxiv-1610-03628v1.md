---
title: "RetiNet: Automatic AMD identification in OCT volumetric data"
source: "http://arxiv.org/pdf/1610.03628v1"
authors:
  - "Stefanos Apostolopoulos"
  - "Carlos Ciller"
  - "Sandro I. De Zanet"
  - "Sebastian Wolf"
  - "Raphael Sznitman"
tags:
  - arxiv
  - CNN
published_in:
  - crazydragon-research-feature
code: https://github.com/thefiddler/retinet
abstract: |
  Optical Coherence Tomography (OCT) provides a unique ability to image the eye
  retina in 3D at micrometer resolution and gives ophthalmologist the ability to
  visualize retinal diseases such as Age-Related Macular Degeneration (AMD).
  While visual inspection of OCT volumes remains the main method for AMD
  identification, doing so is time consuming as each cross-section within the
  volume must be inspected individually by the clinician. In much the same way,
  acquiring ground truth information for each cross-section is expensive and time
  consuming. This fact heavily limits the ability to acquire large amounts of
  ground truth, which subsequently impacts the performance of learning-based
  methods geared at automatic pathology identification. To avoid this burden, we
  propose a novel strategy for automatic analysis of OCT volumes where only
  volume labels are needed. That is, we train a classifier in a semi-supervised
  manner to conduct this task. Our approach uses a novel Convolutional Neural
  Network (CNN) architecture, that only needs volume-level labels to be trained
  to automatically asses whether an OCT volume is healthy or contains AMD. Our
  architecture involves first learning a cross-section pathology classifier using
  pseudo-labels that could be corrupted and then leverage these towards a more
  accurate volume-level classification. We then show that our approach provides
  excellent performances on a publicly available dataset and outperforms a number
  of existing automatic techniques.
snippet: |
  AMD is a degenerative eye condition. OCT is a 3D data set from a scan of an eye.
  This paper shows how training a small CNN on 2D slices of this data,
  and then reusing and freezing the coefficients as part of a larger CNN trained on the
  full data set can produce very good results.

  The first small 2D CNN trained on 2D slices of the 3D data sets only achieves an
  expected  60% accuracy, as the features required for correct identification
  are not present in every slice.

  The coefficients of the first layers in the small model are then used as reused
  as a feature detection layer in the larger network, which is then trained on
  tiled images containing all 2D slices. This resulted in accuracy of over 99%
  out-performing existing implementations.

  It is interesting that a 2D CNN was used to process a 3D dataset by tiling it into
  a single 2D image, rather than using a 3D CNN. This may be due to the limitations
  of available tools, or ease of implementation. It would be interesting to see how a
  3D implementation would compare.

  It would also be interesting to see if a little more accuracy could have been achieved
  by removing the freezing of the feature layer for a few additional epochs of training.
---
