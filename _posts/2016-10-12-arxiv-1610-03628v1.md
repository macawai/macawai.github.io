---
title: "RetiNet: Automatic AMD identification in OCT volumetric data"
source: "http://arxiv.org/pdf/1610.03628v1"
authors:
  - "Stefanos Apostolopoulos"
  - "Carlos Ciller"
  - "Sandro I. De Zanet"
  - "Sebastian Wolf"
  - "Raphael Sznitman"
tags:
  - arxiv
  - needs-commentary
thisweekid: crazydragon
---
## Abstract
>   Optical Coherence Tomography (OCT) provides a unique ability to image the eye
> retina in 3D at micrometer resolution and gives ophthalmologist the ability to
> visualize retinal diseases such as Age-Related Macular Degeneration (AMD).
> While visual inspection of OCT volumes remains the main method for AMD
> identification, doing so is time consuming as each cross-section within the
> volume must be inspected individually by the clinician. In much the same way,
> acquiring ground truth information for each cross-section is expensive and time
> consuming. This fact heavily limits the ability to acquire large amounts of
> ground truth, which subsequently impacts the performance of learning-based
> methods geared at automatic pathology identification. To avoid this burden, we
> propose a novel strategy for automatic analysis of OCT volumes where only
> volume labels are needed. That is, we train a classifier in a semi-supervised
> manner to conduct this task. Our approach uses a novel Convolutional Neural
> Network (CNN) architecture, that only needs volume-level labels to be trained
> to automatically asses whether an OCT volume is healthy or contains AMD. Our
> architecture involves first learning a cross-section pathology classifier using
> pseudo-labels that could be corrupted and then leverage these towards a more
> accurate volume-level classification. We then show that our approach provides
> excellent performances on a publicly available dataset and outperforms a number
> of existing automatic techniques.
> 

NOTES:

Automated diagnosis. Learnt from labeled data using CNN

OCT results in 3D volumes of data. 

Exxamination time consuming and slice-by-slice.

> At its core, our approach uses (1) a taskspecific volume pre-processing
> strategy where we flatten and normalize the data in an OCT-specific manner,
> (2) we then train a 2D B-scan CNN using pseudo-labels that could be corrupted
> in order to pre-learn filters that respond to relevant image features and (3)
> reuse the learned features in a C-scan level CNN that takes a mosaic of
> B-scans as input and classifies the entire C-scan at once.

>To train this network, we first begin by initializing all layer parameters randomly using Glorot Uniform
sampling [42]. We then make use of Extreme Learning [43],

>Our
approach involves a novel two-stage deep learning architecture that in the first phase, focuses on
learning features that are domain specific and then focuses on the volume classification task in the
latter phase.

>Using the learned F EAT URE layers from the previous section,
we include these into our new network as they are invariant to the size of the input and because
ideally, these have learned what anatomical and pathological structures are relevant. These are then
followed by 5 consecutive blocks of convolutional layers, average-pooling and batch normalization.
Finally, we add the CLASSIF ICAT ION layer without transferring weights from RetiNet B. We
define this network configuration as RetiNet C.
To train RetiNet C, we freeze the F EAT URE layers, as these were learned on B-scans and should
respond in the same way as above to preserve useful features extracted in the previous phase. The
rest of the network is then trained using the true labels Yn to learn the remainder of the network
layers.

Split learning into two parts. 
1. Learn feature recognition on slices. (The convolutional layers of the slice classification network)
2. Freeze feature layers, add some more convolution layers apply to multiple tiled slices from one 3D volume and learn more.

 https://github.com/thefiddler/retinet







