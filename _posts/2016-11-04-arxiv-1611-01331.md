---
title: "RenderGAN: Generating Realistic Labeled Data"
source: "http://arxiv.org/pdf/1611.01331v2"
authors:
  - "Leon Sixt"
  - "Benjamin Wild"
  - "Tim Landgraf"
tags:
  - arxiv
  - needs-commentary
published_in:
  - grimsheep-research
abstract: |
  Deep Convolutional Neuronal Networks (DCNN) are showing remarkable
  performance on many computer vision tasks. Due to their large parameter space,
  they require many labeled samples when trained in a supervised setting. The
  costs of annotating data manually can render the usage of DCNNs infeasible. We
  present a novel framework called RenderGAN that can generate large amounts of
  realistic, labeled images by combining a 3D model and the Generative
  Adversarial Network framework. In our approach, image augmentations (e.g.
  lighting, background, and detail) are learned from unlabeled data such that the
  generated images are strikingly realistic while preserving the labels known
  from the 3D model. We apply the RenderGAN framework to generate images of
  barcode-like markers that are attached to honeybees. A DCNN is trained on this
  data only. It performs better on a test set of real data than an equal DCNN
  trained on the limited amounts of real data available.
  
---
