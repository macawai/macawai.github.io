---
title: "Learning to Perform Physics Experiments via Deep Reinforcement Learning"
source: "http://arxiv.org/pdf/1611.01843v1"
authors:
  - "Misha Denil"
  - "Pulkit Agrawal"
  - "Tejas D Kulkarni"
  - "Tom Erez"
  - "Peter Battaglia"
  - "Nando de Freitas"
tags:
  - arxiv
  - needs-commentary
published_in:
  - grimsheep-research
abstract: |
  When encountering novel object, humans are able to infer a wide range of
  physical properties such as mass, friction and deformability by interacting
  with them in a goal driven way. This process of active interaction is in the
  same spirit of a scientist performing an experiment to discover hidden facts.
  Recent advances in artificial intelligence have yielded machines that can
  achieve superhuman performance in Go, Atari, natural language processing, and
  complex control problems, but it is not clear that these systems can rival the
  scientific intuition of even a young child. In this work we introduce a basic
  set of tasks that require agents to estimate hidden properties such as mass and
  cohesion of objects in an interactive simulated environment where they can
  manipulate the objects and observe the consequences. We found that state of art
  deep reinforcement learning methods can learn to perform the experiments
  necessary to discover such hidden properties. By systematically manipulating
  the problem difficulty and the cost incurred by the agent for performing
  experiments, we found that agents learn different strategies that balance the
  cost of gathering information against the cost of making mistakes in different
  situations.
  
---
