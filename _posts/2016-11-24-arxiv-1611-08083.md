---
title: "Survey of Expressivity in Deep Neural Networks"
source: "http://arxiv.org/pdf/1611.08083v1"
authors:
  - "Maithra Raghu"
  - "Ben Poole"
  - "Jon Kleinberg"
  - "Surya Ganguli"
  - "Jascha Sohl-Dickstein"
tags:
  - arxiv
published_in:
  - moonstruckcamel-research
abstract: |
  We survey results on neural network expressivity described in "On the
  Expressive Power of Deep Neural Networks". The paper motivates and develops
  three natural measures of expressiveness, which all display an exponential
  dependence on the depth of the network. In fact, all of these measures are
  related to a fourth quantity, trajectory length. This quantity grows
  exponentially in the depth of the network, and is responsible for the depth
  sensitivity observed. These results translate to consequences for networks
  during and after training. They suggest that parameters earlier in a network
  have greater influence on its expressive power -- in particular, given a layer,
  its influence on expressivity is determined by the remaining depth of the
  network after that layer. This is verified with experiments on MNIST and
  CIFAR-10. We also explore the effect of training on the input-output map, and
  find that it trades off between the stability and expressivity.
  
---
