---
title: "Operational calculus on programming spaces and generalized tensor   networks"
source: "http://arxiv.org/pdf/1610.07690v1"
authors:
  - "Å½iga Sajovic"
  - "Martin Vuk"
tags:
  - arxiv
  - needs-commentary
published_in:
  - psychodonkey-research
abstract: |
  In this paper, we develop the theory of analytic virtual machines, that
  implement analytic programming spaces and operators acting upon them.
  A programming space is a subspace of the function space of maps on the
  virtual memory. We can construct a differential operator on programming spaces
  as we extend the virtual memory to a tensor product of a virtual space with
  tensor algebra of its dual. Extended virtual memory serves by itself as an
  algebra of programs, giving the expansion of the original program as an
  infinite tensor series at program's input values.
  We present a theory of operators on programming spaces, that enables analysis
  of programs and computations on the operator level, which favors general
  implementation. Theory enables approximation and transformations of programs to
  a more appropriate function basis'. We also present several examples of how the
  theory can be used in computer science.
  We generalize neural networks by constructing general tensor networks, that
  naturally exist in virtual memory. Transformations of programs to these
  trainable networks are derived, providing a meaningful way of network
  initialization. Theory opens new doors in program analysis, while fully
  retaining algorithmic control flow. We develop a general procedure which takes
  a program that tests an object for a property and constructs a program that
  imposes that property upon any object. We use it to generalize state of the art
  methods for analyzing neural networks to general programs and tensor networks.
  Expanding upon them, we study dynamics of computation through principles they
  induce into the system.

---
